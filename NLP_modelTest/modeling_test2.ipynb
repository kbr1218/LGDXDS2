{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Test #2\n",
    "### 사용자 입력값 + VOD 줄거리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><hr>\n",
    "\n",
    "## 00. 기본 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 경고 메시지 출력 X\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한글 font 설정\n",
    "import platform\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "#matplotlib 패키지 한글 깨짐 처리 시작\n",
    "#------------------------------------------------------------------------------------\n",
    "# 운영체제별 한글 폰트 설정\n",
    "\n",
    "if platform.system() == 'Darwin': # Mac 환경 폰트 설정\n",
    "    plt.rc('font', family='AppleGothic')\n",
    "elif platform.system() == 'Windows': # Windows 환경 폰트 설정\n",
    "    plt.rc('font', family='Malgun Gothic')\n",
    "    \n",
    "plt.rcParams['axes.unicode_minus'] = False #한글 폰트 사용시 마이너스 폰트 깨짐 해결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 글씨 선명하게 출력하는 설정\n",
    "\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats(\"retina\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><hr>\n",
    "\n",
    "## 01. 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4241, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asset_nm_전처리</th>\n",
       "      <th>ct_cl</th>\n",
       "      <th>genre_of_ct_cl</th>\n",
       "      <th>summary_최신순</th>\n",
       "      <th>최신순</th>\n",
       "      <th>genre_tmdb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>귀멸의 칼날: 남매의 연</td>\n",
       "      <td>영화</td>\n",
       "      <td>애니메이션</td>\n",
       "      <td>혈귀의 습격으로 가족을 잃은 소년 ‘탄지로’. 유일하게 살아남은 여동생 ‘네즈코’마...</td>\n",
       "      <td>2019-03-29</td>\n",
       "      <td>Animation, Action, Fantasy, Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>색에 놀다</td>\n",
       "      <td>영화</td>\n",
       "      <td>에로틱</td>\n",
       "      <td>하얀 색의 순수하고 착한 사랑을 꿈꾸는 25살 모태 솔로 지수. 그녀의 짝사랑 상대...</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Thriller, Drama, Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>돌이킬 수 없는 주말</td>\n",
       "      <td>영화</td>\n",
       "      <td>공포/스릴러</td>\n",
       "      <td>베키는 결혼을 앞두고 친구 수잔과 함께 다트무어로 여행을 떠난다. 그곳에서 신비한 ...</td>\n",
       "      <td>2015-09-18</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    asset_nm_전처리 ct_cl genre_of_ct_cl  \\\n",
       "0  귀멸의 칼날: 남매의 연    영화          애니메이션   \n",
       "1          색에 놀다    영화            에로틱   \n",
       "2    돌이킬 수 없는 주말    영화         공포/스릴러   \n",
       "\n",
       "                                         summary_최신순         최신순  \\\n",
       "0  혈귀의 습격으로 가족을 잃은 소년 ‘탄지로’. 유일하게 살아남은 여동생 ‘네즈코’마...  2019-03-29   \n",
       "1  하얀 색의 순수하고 착한 사랑을 꿈꾸는 25살 모태 솔로 지수. 그녀의 짝사랑 상대...  2017-01-01   \n",
       "2  베키는 결혼을 앞두고 친구 수잔과 함께 다트무어로 여행을 떠난다. 그곳에서 신비한 ...  2015-09-18   \n",
       "\n",
       "                             genre_tmdb  \n",
       "0  Animation, Action, Fantasy, Thriller  \n",
       "1              Thriller, Drama, Romance  \n",
       "2                Drama, Horror, Mystery  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies = pd.read_csv('..\\data\\movies_4000_tmdb_genre.csv')\n",
    "print(movies.shape)   # (4241, 6)\n",
    "movies.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genre_of_ct_cl\n",
       "드라마        1011\n",
       "액션/어드벤쳐     977\n",
       "공포/스릴러      639\n",
       "성인          340\n",
       "멜로          329\n",
       "코미디         265\n",
       "애니메이션       169\n",
       "SF/환타지      159\n",
       "다큐멘터리       126\n",
       "기타           88\n",
       "무협           37\n",
       "로맨틱코미디       37\n",
       "에로틱          35\n",
       "단편           12\n",
       "서부            7\n",
       "뮤지컬           6\n",
       "역사            2\n",
       "인물            2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies['genre_of_ct_cl'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *>> 장르가 '성인' 또는 '기타'인 행와 장르의 value_counts가 40개 미만인 행은 삭제*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 장르의 수 를 genre_counts 변수에 저장\n",
    "genre_counts = movies['genre_of_ct_cl'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 삭제할 조건 생성\n",
    "delete_conditions = (movies['genre_of_ct_cl'] == '성인') | (movies['genre_of_ct_cl'] == '기타') | (movies['genre_of_ct_cl'].isin(genre_counts[genre_counts < 40].index))\n",
    "filtered_movies = movies[~delete_conditions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3675, 6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "genre_of_ct_cl\n",
       "드라마        1011\n",
       "액션/어드벤쳐     977\n",
       "공포/스릴러      639\n",
       "멜로          329\n",
       "코미디         265\n",
       "애니메이션       169\n",
       "SF/환타지      159\n",
       "다큐멘터리       126\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결과 확인\n",
    "print(filtered_movies.shape)\n",
    "filtered_movies['genre_of_ct_cl'].value_counts()\n",
    "\n",
    "### (4241, 6) >> (3675, 6) >> 566개의 행 삭제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *>> 사용하지 않을 열 drop*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asset_nm_전처리</th>\n",
       "      <th>genre_of_ct_cl</th>\n",
       "      <th>summary_최신순</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>귀멸의 칼날: 남매의 연</td>\n",
       "      <td>애니메이션</td>\n",
       "      <td>혈귀의 습격으로 가족을 잃은 소년 ‘탄지로’. 유일하게 살아남은 여동생 ‘네즈코’마...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>돌이킬 수 없는 주말</td>\n",
       "      <td>공포/스릴러</td>\n",
       "      <td>베키는 결혼을 앞두고 친구 수잔과 함께 다트무어로 여행을 떠난다. 그곳에서 신비한 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>섹스 앤 머니</td>\n",
       "      <td>액션/어드벤쳐</td>\n",
       "      <td>갱단 두목 페페는 라이벌 갱단 두목 조조와 세력 다툼을 벌이다 쫓기는 신세가 된다....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    asset_nm_전처리 genre_of_ct_cl  \\\n",
       "0  귀멸의 칼날: 남매의 연          애니메이션   \n",
       "2    돌이킬 수 없는 주말         공포/스릴러   \n",
       "3        섹스 앤 머니        액션/어드벤쳐   \n",
       "\n",
       "                                         summary_최신순  \n",
       "0  혈귀의 습격으로 가족을 잃은 소년 ‘탄지로’. 유일하게 살아남은 여동생 ‘네즈코’마...  \n",
       "2  베키는 결혼을 앞두고 친구 수잔과 함께 다트무어로 여행을 떠난다. 그곳에서 신비한 ...  \n",
       "3  갱단 두목 페페는 라이벌 갱단 두목 조조와 세력 다툼을 벌이다 쫓기는 신세가 된다....  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_to_drop = ['ct_cl', '최신순', 'genre_tmdb']\n",
    "drop_movies = filtered_movies.drop(columns=col_to_drop, axis=1)\n",
    "\n",
    "drop_movies.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><hr>\n",
    "\n",
    "## 02. 한글 텍스트 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 줄거리 null값 확인\n",
    "drop_movies['summary_최신순'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정규표현식을 이용해 숫자를 공백으로 변경 (정규 표현식으로 \\d는 숫자 의미)\n",
    "drop_movies['summary_최신순'] = drop_movies['summary_최신순'].apply(lambda x : re.sub(r\"\\d+\", \"\", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정규표현식을 이용해 특수문자를 공백으로 변경\n",
    "drop_movies['summary_최신순'] = drop_movies['summary_최신순'].apply(lambda x: re.sub(r\"[^가-힣a-zA-Z0-9\\s]\", \"\", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okt 객체 생성\n",
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def okt_tokenizer(text):\n",
    "    # 입력 인자로 들어온 텍스트를 형태소 단어로 토큰화해 리스트 형태로 변환\n",
    "    tokens_ko = okt.morphs(text)\n",
    "    return tokens_ko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# okt 객체의 morphs() 객체를 이용한 tokenizer 사용, ngram_rage는 (1, 2)\n",
    "tfidf_vect = TfidfVectorizer(tokenizer=okt_tokenizer,\n",
    "                             ngram_range=(1, 2),  # unigram + bigram\n",
    "                             min_df=2,\n",
    "                             max_df=0.85)\n",
    "tfidf_vect.fit(drop_movies['summary_최신순'])\n",
    "tfidf_matrix = tfidf_vect.transform(drop_movies['summary_최신순'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><hr>\n",
    "\n",
    "## 03. 토큰화된 문서를 장르 기준으로 LDA 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopwords 가져오기\n",
    "with open('..\\data\\stopwords\\combined_stopwords.txt', 'r', encoding='utf-8') as stopwords_file:\n",
    "    lda_stopwords = stopwords_file.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genre_of_ct_cl\n",
       "드라마        1011\n",
       "액션/어드벤쳐     977\n",
       "공포/스릴러      639\n",
       "멜로          329\n",
       "코미디         265\n",
       "애니메이션       169\n",
       "SF/환타지      159\n",
       "다큐멘터리       126\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_movies['genre_of_ct_cl'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 장르별 데이터 분리\n",
    "genres = ['드라마', '액션/어드벤쳐', '공포/스릴러', '애니메이션', '코미디', '멜로','SF/환타지', '다큐멘터리']\n",
    "\n",
    "# 장르별 데이터프레임 생성\n",
    "genre_dfs = {genre: drop_movies[drop_movies['genre_of_ct_cl'] == genre] for genre in genres}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불용어 리스트에 해지, 시청, 가능, 서비스 추가\n",
    "additional_stop_words = ['해지', '시청', '가능', '서비스', '가능합니다', '평생', '소장',\n",
    "                         'of', 'the', 'a', 'in', 'is', 'her', 'and', 'to', 'it', 'he', 'she', 'his',\n",
    "                         'on', 'who', 'with']\n",
    "lda_stopwords.extend(additional_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "드라마 문서 개수: 1011\n",
      "액션/어드벤쳐 문서 개수: 977\n",
      "공포/스릴러 문서 개수: 639\n",
      "애니메이션 문서 개수: 169\n",
      "코미디 문서 개수: 265\n",
      "멜로 문서 개수: 329\n",
      "SF/환타지 문서 개수: 159\n",
      "다큐멘터리 문서 개수: 126\n"
     ]
    }
   ],
   "source": [
    "lda_results = {}\n",
    "\n",
    "for genre, drop_movies in genre_dfs.items():\n",
    "    # 문서 개수 확인\n",
    "    doc_count = len(drop_movies['summary_최신순'])\n",
    "    print(f\"{genre} 문서 개수: {doc_count}\")\n",
    "    # 2. 토픽 모델링을 위한 전처리\n",
    "    # TF-IDF로 변환된 데이터를 장르별로 LDA에 입력할 수 있는 형태로 준비\n",
    "    \n",
    "    # LDA는 Bag-of-Words(BoW) 지원하므로 CountVectorizer로 BoW를 생성\n",
    "    vectorizer = CountVectorizer(stop_words=lda_stopwords,\n",
    "                                 tokenizer=okt_tokenizer,\n",
    "                                 max_features=5000,\n",
    "                                 max_df=0.80,\n",
    "                                 min_df=2,\n",
    "                                 # ngram_range=(1, 2)\n",
    "                                )\n",
    "    bow_matrix = vectorizer.fit_transform(drop_movies['summary_최신순'])\n",
    "    \n",
    "    # 3. LDA 모델 생성 및 학습\n",
    "    # LatentDirichletAllocation을 사용하여 장르별로 토픽을 추출\n",
    "    # 8개의 토픽 추출\n",
    "    lda = LatentDirichletAllocation(n_components=5, random_state=42)\n",
    "    lda.fit(bow_matrix)\n",
    "    \n",
    "    # 4. 토픽별 주요 단어 추출\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    topics = {}\n",
    "    for topic_idx, topic in enumerate(lda.components_):\n",
    "        top_words = [feature_names[i] for i in topic.argsort()[:-11:-1]]  # 상위 10개 단어\n",
    "        topics[f\"Topic {topic_idx + 1}\"] = top_words\n",
    "    \n",
    "    lda_results[genre] = topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 드라마 장르 ---\n",
      "Topic 1: 사람, 시작, 적, 남편, 친구, 가족, 사랑, 아들, 남자, 다시\n",
      "Topic 2: 시작, 마을, 적, 아버지, 사람, 집, 사랑, 친구, 엄마, 마음\n",
      "Topic 3: 적, 사랑, 시작, 사람, 삶, 딸, 집, 남자, 엄마, 여자\n",
      "Topic 4: 시작, 적, 소녀, 사건, 사람, 친구, 학교, 죽음, 마음, 곳\n",
      "Topic 5: 시작, 사랑, 적, 사건, 사람, 이야기, 아들, 영화, 집, 꿈\n",
      "\n",
      "\n",
      "--- 액션/어드벤쳐 장르 ---\n",
      "Topic 1: 경찰, 시작, 조직, 적, 마약, 범죄, 사건, 팀, 가족, 목숨\n",
      "Topic 2: 시작, 적, 사람, 세계, 테러, 조직, 딸, 납치, 작전, 친구\n",
      "Topic 3: 시작, 적, 사람, 세상, 명, 곳, 가문, 황제, 요, 미국\n",
      "Topic 4: 사건, 시작, 적, 부대, 임무, 딸, 작전, 살인, 조직, 목숨\n",
      "Topic 5: 시작, 사건, 지구, 사람, 곳, 힘, 중국, 비밀, 적, 천\n",
      "\n",
      "\n",
      "--- 공포/스릴러 장르 ---\n",
      "Topic 1: 집, 사람, 시작, 곳, 마을, 적, 친구, 비밀, 가족, 사건\n",
      "Topic 2: 사건, 적, 집, 살인, 시작, 사람, 친구, 죽음, 발견, 마을\n",
      "Topic 3: 시작, 사건, 적, 집, 사람, 딸, 친구, 곳, 남편, 아들\n",
      "Topic 4: 잭, 친구, 사건, 사람, 대니, 시작, 집, 남자, 적, 병원\n",
      "Topic 5: 시작, 적, 사건, 살인, 발견, 가족, 남자, 엄마, 사람, 집\n",
      "\n",
      "\n",
      "--- 애니메이션 장르 ---\n",
      "Topic 1: 친구, 세상, 모험, 도시, 슈퍼, 있을까, 납치, 빼꼼, 비밀, 꽁꽁\n",
      "Topic 2: 친구, 세계, 소녀, 마을, 사람, 모험, 곳, 집, 세상, 향\n",
      "Topic 3: 세상, 친구, 왕자, 숲, 있을까, 마법, 시작, 드래곤, 인간, 마을\n",
      "Topic 4: 시작, 사람, 사건, 생활, 꿈, 세계, 북극, 다시, 있을까, 적\n",
      "Topic 5: 시작, 친구, 가족, 위기, 소년, 적, 비밀, 소녀, 꿈, 문\n",
      "\n",
      "\n",
      "--- 코미디 장르 ---\n",
      "Topic 1: 시작, 가족, 인생, 생활, 적, 피터, 사랑, 케빈, 없이, 집\n",
      "Topic 2: 친구, 원, 남자, 정도, 향, 시작, 사람, 아버지, 놈, 잔\n",
      "Topic 3: 사람, 테드, 달리, 시작, 마을, 개, 사랑, 적, 집, 남편\n",
      "Topic 4: 적, 시작, 결혼, 집, 사건, 사랑, 사람, 학교, 친구, 곳\n",
      "Topic 5: 시작, 사랑, 작업, 미정, 친구, 사람, 에는, 사건, 적, 명의\n",
      "\n",
      "\n",
      "--- 멜로 장르 ---\n",
      "Topic 1: 사랑, 시작, 적, 남자, 마음, 사람, 여자, 다시, 영화, 감정\n",
      "Topic 2: 사람, 시작, 사랑, 향, 마음, 친구, 여자, 집, 말, 남자\n",
      "Topic 3: 사람, 사랑, 적, 카, 시작, 연인, 아내, 마음, 남자, 손\n",
      "Topic 4: 사랑, 시작, 사람, 마음, 남자, 친구, 첫, 테, 사이, 이야기\n",
      "Topic 5: 적, 사랑, 영화, 친구, 집, 시작, 어머니, 남자, 아버지, 사람\n",
      "\n",
      "\n",
      "--- SF/환타지 장르 ---\n",
      "Topic 1: 지구, 인간, 적, 우주, 존재, 남자, 로봇, 소, 아버지, 인해\n",
      "Topic 2: 지구, 해리, 사람, 곳, 세상, 분파, 미래, 마법, 우주선, 인류\n",
      "Topic 3: 사건, 집, 사람, 생각, 적, 박사, 시작, 엄마, 제이슨, 모나\n",
      "Topic 4: 인간, 시작, 탈출, 우주, 적, 발견, 곳, 있던, 군, 생명체\n",
      "Topic 5: 인류, 세계, 시작, 지구, 우주, 적, 요원, 짐, 행성, 곳\n",
      "\n",
      "\n",
      "--- 다큐멘터리 장르 ---\n",
      "Topic 1: 적, 시작, 말, 후보, 팬, 했다, 개, 하지, 선수, 스타\n",
      "Topic 2: 적, 사람, 씨, 향, 한국, 네팔, 현, 역사, 사이, 여왕\n",
      "Topic 3: 영화, 적, 사람, 가장, 이야기, 세계, 공연, 삶, 대한, 시작\n",
      "Topic 4: 적, 시작, 이자, 마마, 마지막, 새, 무, 세계, 담은, 사랑\n",
      "Topic 5: 삶, 이야기, 사람, 대한, 인생, 영화, 통해, 사랑, 세상, 시작\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5. 결과 출력\n",
    "for genre, topics in lda_results.items():\n",
    "    print(f\"--- {genre} 장르 ---\")\n",
    "    for topic, words in topics.items():\n",
    "        print(f\"{topic}: {', '.join(words)}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 개별 토픽별로 각 word 피처가 얼마나 많이 그 토픽에 할당되었는지에 대한 수치를 가지고 있음\n",
    "# 높을 값일수록 해당 word 피쳐는 그 토픽의 중심 word가 됨\n",
    "# print(lda.components_.shape)\n",
    "# lda.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## 04. 토픽별로 연관도가 높은 순으로 word 나열"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, no_top_words):\n",
    "    for topic_index, topic in enumerate(model.components_):\n",
    "        print(\"Topic #\", topic_index)\n",
    "        \n",
    "        # components_ array에서 가장 값이 큰 순으로 정렬했을 때 그 값의 array 인덱스 반환\n",
    "        topic_word_indexes = topic.argsort()[::-1]\n",
    "        top_indexes = topic_word_indexes[:no_top_words]\n",
    "        \n",
    "        # top_indexes 대상인 인덱스별로 feature_names에 해당하는 word feature 추출 후 join으로 concat\n",
    "        feature_concat = ' '.join([feature_names[i] for i in top_indexes])\n",
    "        print(feature_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CountVectorizer 객체 내의 전체 word 명칭을 get_features_names_out()를 통해 추출\n",
    "feature_names = vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic # 0\n",
      "적 시작 말 후보 팬 했다 개 하지 선수 스타 북 세계 했던 어머니 무대\n",
      "Topic # 1\n",
      "적 사람 씨 향 한국 네팔 현 역사 사이 여왕 도시 세상 비 충격 교육\n",
      "Topic # 2\n",
      "영화 적 사람 가장 이야기 세계 공연 삶 대한 시작 주년 더 교황 과학자 한국\n",
      "Topic # 3\n",
      "적 시작 이자 마마 마지막 새 무 세계 담은 사랑 이야기 문제 도시 무대 에는\n",
      "Topic # 4\n",
      "삶 이야기 사람 대한 인생 영화 통해 사랑 세상 시작 적 다큐멘터리 가족 가장 했다\n"
     ]
    }
   ],
   "source": [
    "# 토픽별 가장 연관도가 높은 word를 15개만 추출\n",
    "display_topics(lda, feature_names, 15)\n",
    "\n",
    "##### 각 토픽(topic)이 해당 텍스트 집합에서 나타내는 잠재적인 주제를 나타냄\n",
    "##### 각 토픽에 포함된 단어는 해당 주제를 구성하는 주요 단어들로, 이를 기반하여 토픽을 해석할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## 05. 추천에 적용하기\n",
    "\n",
    "1. LDA는 각 콘텐츠(영화 줄거리)에 대해 토픽 분포 계산\n",
    "2. 사용자의 선호 토픽 결정\n",
    "    - 사용자의 입력(예: \"액션 영화를 추천해줘\")을 바탕으로 해당 토픽을 선택\n",
    "    - 또는 사용자가 이전에 시청한 콘텐츠의 토픽 분포를 활용하여 선호도를 추론\n",
    "3. 추천 콘텐츠 선정\n",
    "    - LDA 결과에서 사용자의 선호 토픽과 가장 유사한 콘텐츠를 계산하여 추천\n",
    "    - 코사인 유사도 사용\n",
    "4. 결과 반환\n",
    "    - 유사도가 높은 콘텐츠(영화) 상위 5개를 추천"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_topic_with_movies(user_input, vectorizer, lda_model, feature_names, movies, no_top_words=10):\n",
    "    # 사용자 입력을 바탕으로 가장 유사한 토픽을 추천\n",
    "    # 1. 사용자 입력 텍스트를 BoW(Bag of Words)로 변환\n",
    "    user_input_bow = vectorizer.transform([user_input])\n",
    "    \n",
    "    # 2. LDA 모델을 통해 사용자 입력의 토픽 분포 추출\n",
    "    user_topic_distribution = lda_model.transform(user_input_bow)\n",
    "    \n",
    "    # 3. 가장 높은 확률을 가진 토픽 인덱스 선택\n",
    "    recommended_topic_idx = np.argmax(user_topic_distribution)\n",
    "    \n",
    "    # 4. 해당 토픽의 주요 단어 추출\n",
    "    topic_terms = lda_model.components_[recommended_topic_idx]\n",
    "    top_word_indices = topic_terms.argsort()[:-no_top_words - 1:-1]\n",
    "    top_words = [feature_names[i] for i in top_word_indices]\n",
    "    \n",
    "    print(f\"추천 토픽: Topic #{recommended_topic_idx + 1}\")\n",
    "    print(f\"주요 단어: {', '.join(top_words)}\")\n",
    "    \n",
    "    # 5. 영화 데이터에서 해당 토픽의 영화 선택\n",
    "    topic_distributions = lda_model.transform(vectorizer.transform(movies['summary_최신순']))  # 영화별 토픽 분포\n",
    "    topic_movies = movies[np.argmax(topic_distributions, axis=1) == recommended_topic_idx]\n",
    "    \n",
    "    # 랜덤으로 3개 추출\n",
    "    recommended_movies = topic_movies.sample(n=min(3, len(topic_movies)))\n",
    "    print(\"\\n추천 영화:\")\n",
    "    print(recommended_movies[['asset_nm_전처리']])\n",
    "    \n",
    "    return recommended_topic_idx, top_words, recommended_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "추천 토픽: Topic #3\n",
      "주요 단어: 영화, 적, 사람, 가장, 이야기, 세계, 공연, 삶, 대한, 시작\n",
      "\n",
      "추천 영화:\n",
      "         asset_nm_전처리\n",
      "2830  나는 마을 방과후 교사입니다\n",
      "863             머슴 바울\n",
      "311        의혹을 파는 사람들\n"
     ]
    }
   ],
   "source": [
    "recommended_topic_idx, top_words, recommended_movies = recommend_topic_with_movies(\n",
    "    user_input='가장 이야기 세계 공연',\n",
    "    vectorizer=vectorizer,\n",
    "    lda_model=lda,\n",
    "    feature_names=feature_names,\n",
    "    movies=drop_movies\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00815096, 0.96746229, 0.00815803, 0.00810138, 0.00812733],\n",
       "       [0.00961836, 0.00960672, 0.96143457, 0.00967035, 0.00966999],\n",
       "       [0.0255923 , 0.02520889, 0.89629285, 0.02609128, 0.02681468],\n",
       "       [0.01678379, 0.01681218, 0.93245745, 0.01687777, 0.01706882],\n",
       "       [0.01056484, 0.01056791, 0.01063257, 0.01061219, 0.95762249],\n",
       "       [0.24519654, 0.00381366, 0.7432946 , 0.00383023, 0.00386498],\n",
       "       [0.01367882, 0.01383822, 0.01350489, 0.01353063, 0.94544744],\n",
       "       [0.01123035, 0.01119012, 0.01125864, 0.95513882, 0.01118207],\n",
       "       [0.73981999, 0.24601115, 0.00474322, 0.00470261, 0.00472303],\n",
       "       [0.98238722, 0.00439152, 0.00441163, 0.00441428, 0.00439535]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LDA 결과로 콘텐츠-토픽 분포 추출\n",
    "topic_distributions = lda.transform(bow_matrix) # bow_matrix는 CountVectorizer로 변환된 콘텐츠 데이터\n",
    "topic_distributions[:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

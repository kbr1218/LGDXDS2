{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM ModelTest #2\n",
    "#### *ibm-granite/granite-embedding-278m-multilingual*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API KEY를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# API KEY 정보로드\n",
    "load_dotenv()\n",
    "GEMINI_API_KEY = os.getenv('API_KEY_GEMINI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "dx_project\n"
     ]
    }
   ],
   "source": [
    "# LangSmith 추적을 설정합니다. https://smith.langchain.com\n",
    "# !pip install langchain-teddynote\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(\"dx_project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "# 랭체인 환경 설정\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "#from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "# from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnableLambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서의 수: 3901\n"
     ]
    }
   ],
   "source": [
    "### 01. CSV 파일에서 문서 로드 ###\n",
    "loader = CSVLoader('../data/movie_4000_preprocessed.csv', encoding='utf8')\n",
    "docs = loader.load()\n",
    "print(f\"문서의 수: {len(docs)}\")\n",
    "\n",
    "### 02. pandas로 데이터프레임 칼럼명 가져오기\n",
    "csv_path = '../data/movie_4000_preprocessed.csv'\n",
    "df = pd.read_csv(csv_path, encoding='utf8')\n",
    "colnames = df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서의 수: 3901\n",
      "[메타데이터 예시]\n",
      " {'title': '아름답다', 'genre': '드라마'}\n"
     ]
    }
   ],
   "source": [
    "### 03. 메타데이터 추가 ###\n",
    "docs = []\n",
    "for _, row in df.iterrows():\n",
    "  # 필요한 메타데이터 설정\n",
    "  metadata = {\n",
    "    'title': row['movie_title'],\n",
    "    'genre': row['genre']\n",
    "  }\n",
    "  # 각 행의 데이터를 문서로 변환\n",
    "  doc = Document(\n",
    "    page_content=str(row.to_dict()),\n",
    "    metadata=metadata\n",
    "  )\n",
    "  docs.append(doc)\n",
    "\n",
    "print(f\"문서의 수: {len(docs)}\")\n",
    "print('[메타데이터 예시]\\n', docs[100].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split된 문서의 수: 3901\n"
     ]
    }
   ],
   "source": [
    "### 04. 데이터 청크 나누기 ###\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "  chunk_size=1090, chunk_overlap=0\n",
    ")\n",
    "splits = text_splitter.split_documents(docs)\n",
    "print(\"split된 문서의 수:\", len(splits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_15068\\3636801640.py:3: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name='ibm-granite/granite-embedding-278m-multilingual')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "365785b9602941c69a2c592192ca25b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5efd5fadd2174b47ae65afba0af571c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/610k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6f77b054b0e46ea9b16053788558b0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/54.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ad7c4f0fb5344498e73aabd69602ae2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/698 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "107b28a559fb4611950907f15fa00210",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/556M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ee78d2141b04eddb1efc6fd4e7347de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/418 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe38b27bb58a47e5aa9215d3fec35809",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3555902333024593bc1ece88559cc5a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.08M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b64833d35573436294c6aab1fc7abffb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\workspaces\\proj\\forllm\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0a471d5e4384572843ae36fe56e7d8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/191 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### 05. 임베딩 모델 생성\n",
    "# https://huggingface.co/ibm-granite/granite-embedding-278m-multilingual\n",
    "embeddings = HuggingFaceEmbeddings(model_name='ibm-granite/granite-embedding-278m-multilingual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_15068\\1735004291.py:2: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectorstore = Chroma(persist_directory=\"../data/movie_4000_vectorstore_2\", embedding_function=embeddings)\n"
     ]
    }
   ],
   "source": [
    "# Chroma 벡터스토어 로드\n",
    "vectorstore = Chroma(persist_directory=\"../data/movie_4000_vectorstore_2\", embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 사용자 입력값 유형 분류용 프롬프트\n",
    "classification_template = \"\"\"사용자의 입력을 다음 세 가지 범주 중 하나로 분류하세요:\n",
    "1️⃣ **\"정보검색\"**: 특정 영화, 드라마, 배우, 감독, 러닝타임, 개봉 연도, 수상 내역, 필모그래피 등 **사실적인 정보를 찾는 질문**\n",
    "   - 기대되는 응답 예시: 배우가 출연한 드라마/영화 목록, 특정 연도의 개봉작 리스트 등\n",
    "2️⃣ **\"추천요청\"**: 특정 장르, 배우, 테마(예: 좀비, 시간여행), 감성(예: 힐링, 긴장감) 등에 대한 **추천을 요청하는 질문**\n",
    "   - 기대되는 응답 예시: 특정 조건을 만족하는 영화/드라마 추천\n",
    "3️⃣ **\"일반대화\"**: 서비스와 무관한 일반적인 대화 (예: 날씨, AI 관련 질문, 잡담)\n",
    "\n",
    "질문과 관련된 주요 키워드를 반환하세요.\n",
    "\n",
    "#### **예시 형식**\n",
    "{{\n",
    "  \"type\": \"정보검색\",\n",
    "  \"keywords\": [\"한효주\", \"드라마\", \"출연\"]\n",
    "}}\n",
    "\n",
    "<question>\n",
    "{question}\n",
    "</question>\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(classification_template)\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# langchain 체인 구성\n",
    "classification_chain = (\n",
    "  prompt\n",
    "  | llm\n",
    "  | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"type\": \"정보검색\",\n",
      "  \"keywords\": [\"한효주\", \"드라마\", \"출연\"]\n",
      "}\n",
      "{\n",
      "  \"type\": \"추천요청\",\n",
      "  \"keywords\": [\"스파이더맨\", \"영화\", \"추천\"]\n",
      "}\n",
      "{\n",
      "  \"type\": \"추천요청\",\n",
      "  \"keywords\": [\"코미디\", \"호러\", \"영화\", \"추천\"]\n",
      "}\n",
      "{\n",
      "  \"type\": \"일반대화\",\n",
      "  \"keywords\": [\"심심해\"]\n",
      "}\n",
      "{\n",
      "  \"type\": \"일반대화\",\n",
      "  \"keywords\": [\"우울\", \"감정\"]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# 예상 정보검색\n",
    "print(classification_chain.invoke({\"question\": \"한효주가 나오는 드라마 알려줘.\"}))\n",
    "print(classification_chain.invoke({\"question\": \"스파이더맨 영화를 보고싶어\"}))\n",
    "\n",
    "# 추천 요청\n",
    "print(classification_chain.invoke({\"question\": \"코미디면서 호러 장르의 영화를 추천해줘\"}))\n",
    "\n",
    "# 일반대화화\n",
    "print(classification_chain.invoke({\"question\": \"심심해\"}))\n",
    "print(classification_chain.invoke({\"question\": \"오늘은 우울한걸\"}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON 결과를 올바르게 파싱하는 함수\n",
    "def preprocess_classification_result(question: str):\n",
    "    classification_result = classification_chain.invoke({\"question\": question})\n",
    "\n",
    "    # JSON 문자열에서 ```json``` 제거 (정규식 활용)\n",
    "    json_match = re.search(r'```json\\s*(\\{.*?\\})\\s*```', classification_result, re.DOTALL)\n",
    "    if json_match:\n",
    "        clean_json_str = json_match.group(1)                       # 중괄호 {} 내부만 추출\n",
    "    else:\n",
    "        clean_json_str = classification_result                     # ```json``` 태그가 없을 경우 그대로 사용\n",
    "\n",
    "    # JSON 문자열을 dict 자료형으로 변환\n",
    "    try:\n",
    "        classification_data = json.loads(clean_json_str)\n",
    "        type_value = classification_data.get(\"type\", \"일반대화\")   # 기본값을 '일반대화'로 설정\n",
    "        keywords = classification_data.get(\"keywords\", [])         # 기본값을 빈 리스트로 설정\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"⚠️ JSONDecodeError: {e}\")  # JSON 변환 오류 확인\n",
    "        type_value = \"일반대화\"           # JSON 변환 오류 시 기본값 설정\n",
    "        keywords = []\n",
    "    \n",
    "    return {\"type\": type_value, \"keywords\": keywords}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_chain 생성 (사용자의 의미없는 입력값에 대해 정해진 답변을 할 때)\n",
    "# 프롬프트 템플릿 설정\n",
    "default_template = \"\"\"\n",
    "\"You are a chatbot that must always respond with '🐶: 멍멍!'.\n",
    "No matter what question the user asks, always reply with '🐶: 멍멍!'\"\n",
    "\n",
    "[사용자 입력과 분류 결과]:\n",
    "{classification_result}\n",
    "\"\"\"\n",
    "default_prompt = ChatPromptTemplate.from_template(default_template)\n",
    "\n",
    "default_llm = ChatOpenAI(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  temperature=0)\n",
    "\n",
    "# langchain 체인 구성\n",
    "default_chain = (\n",
    "  {\"classification_result\": RunnablePassthrough()}\n",
    "  | default_prompt               # 하나로 만든 문서를 prompt에 넘겨주고\n",
    "  | default_llm            # llm이 원하는 답변을 만듦\n",
    "  | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# langchain router\n",
    "##  정보검색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색기 생성\n",
    "# mmr 중복 피하기, 문서의관련성과 차별성 고려, \n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"mmr\",   \n",
    "    search_kwargs={\"k\": 20,              # 반환할 문서 수 (default: 4)\n",
    "                   \"fetch_k\": 50,       # MMR 알고리즘에 전달할 문서 수\n",
    "                   \"lambda_mult\": 0.5,    # 결과 다양성 조절 (default: 0.5),\n",
    "                   }\n",
    ")\n",
    "\n",
    "info_template = \"\"\"\n",
    "사용자가 영화나 드라마에 대한 정보를 검색하고 있습니다.\n",
    "다음 사용자 질문과 관련된 **가장 적절한 문서(컨텐츠)를 벡터스토어에서 검색**한 후, \n",
    "해당 정보를 출력하세요.\n",
    "\n",
    "### **예시 응답 형식**\n",
    "{{\n",
    "  \"title\": \"인셉션\",\n",
    "  \"genre\": [\"SF\", \"스릴러\"]\n",
    "}}\n",
    "\n",
    "[사용자 입력과 분류 결과]:\n",
    "{classification_result}\n",
    "\n",
    "[Context]: \n",
    "{retrieved_context} \n",
    "Answer:\n",
    "\n",
    "\"\"\"\n",
    "info_prompt = ChatPromptTemplate.from_template(info_template)\n",
    "info_chain = (\n",
    "    {\n",
    "      \"classification_result\": RunnablePassthrough(),\n",
    "      \"retrieved_context\": retriever\n",
    "    }\n",
    "    |info_prompt\n",
    "    |llm\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 테디"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def route(info):\n",
    "    # 주제에 \"정보검색\"이 포함되어 있는 경우\n",
    "    if \"정보검색\" in info[\"topic\"].lower():\n",
    "        return info_chain\n",
    "    # 주제에 \"추천요청\"이 포함되어 있는 경우\n",
    "    elif \"추천요청\" in info[\"topic\"].lower():\n",
    "        return recommend_chain\n",
    "    # 일반대화화\n",
    "    else:\n",
    "        return general_chain\n",
    "    \n",
    "# from operator import itemgetter\n",
    "# from langchain_core.runnables import RunnableBranch\n",
    "\n",
    "# branch = RunnableBranch(\n",
    "#     (lambda x: \"정보검색\" in x[\"topic\"].lower(), info_chain),\n",
    "#     (lambda x: \"추천요청\" in x[\"topic\"].lower(), recommend_chain),\n",
    "#     general_chain,\n",
    "# )\n",
    "# full_chain = (\n",
    "#     {\"topic\": rag_chain, \"question\": itemgetter(\"question\")} | branch | StrOutputParser()\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_chain = (\n",
    "    {\"topic\": rag_chain, \"question\": itemgetter(\"question\")}\n",
    "    | RunnableLambda(\n",
    "        route\n",
    "    )\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'retriever' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mretriever\u001b[49m\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m한효주\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'retriever' is not defined"
     ]
    }
   ],
   "source": [
    "retriever.invoke(\"한효주\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "full_chain.invoke({\"question\": \"한효주가 나오는 드라마 알려줘.\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_user_input(classification_result: dict):\n",
    "    # 사용자의 입력 유형 분류\n",
    "    print(classification_result)\n",
    "    classification_data = classification_result.get(\"classification_result\", {})  # 내부 딕셔너리 추출\n",
    "    type_value = classification_data.get(\"type\", \"일반대화\")  # 기본값 설정\n",
    "    keywords = classification_data.get(\"keywords\", [])  # 기본값 설정\n",
    "    \n",
    "    print(f\"===================== Type: {type_value}\")\n",
    "    print(f\"===================== Keywords: {keywords}\")\n",
    "\n",
    "    if type_value == '정보검색':\n",
    "        return info_chain.invoke(str(classification_result))\n",
    "    elif type_value == '추천요청':\n",
    "        return \"추천요청 체인 실행은 여기!!\"\n",
    "    else:\n",
    "        return default_chain.invoke({\"classification_result\": classification_result})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_chain = (\n",
    "  {\"classification_result\": RunnableLambda(preprocess_classification_result),# type keyword: dic\n",
    "   \"question\":itemgetter(\"question\")}\n",
    "  | RunnableLambda(process_user_input)\n",
    "  | StrOutputParser()  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classification_result': {'type': '일반대화', 'keywords': ['심심']}, 'question': '심심'}\n",
      "===================== Type: 일반대화\n",
      "===================== Keywords: ['심심']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'🐶: 멍멍!'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_chain.invoke({\"question\":\"심심\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수정사항..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lgdxteam2-aSyY5fLw-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
